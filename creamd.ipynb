{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXcxWEg40odu",
        "outputId": "e095c459-2b4f-4cf9-a4ba-4668936aad1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.2555 - loss: 11.1935 - val_accuracy: 0.2881 - val_loss: 2.5108\n",
            "Epoch 2/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4419 - loss: 1.5278 - val_accuracy: 0.3378 - val_loss: 2.2556\n",
            "Epoch 3/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5152 - loss: 1.3124 - val_accuracy: 0.3345 - val_loss: 2.0549\n",
            "Epoch 4/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.5753 - loss: 1.1470 - val_accuracy: 0.3539 - val_loss: 1.7621\n",
            "Epoch 5/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.6763 - loss: 0.8978 - val_accuracy: 0.4056 - val_loss: 1.6830\n",
            "Epoch 6/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6952 - loss: 0.8295 - val_accuracy: 0.3848 - val_loss: 1.8542\n",
            "Epoch 7/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7685 - loss: 0.6503 - val_accuracy: 0.3109 - val_loss: 3.7635\n",
            "Epoch 8/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7570 - loss: 0.6582 - val_accuracy: 0.3264 - val_loss: 2.7045\n",
            "Epoch 9/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7246 - loss: 0.8100 - val_accuracy: 0.3586 - val_loss: 2.5285\n",
            "Epoch 10/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.4393 - val_accuracy: 0.4137 - val_loss: 2.2214\n",
            "Epoch 11/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.3495 - val_accuracy: 0.4124 - val_loss: 2.4045\n",
            "Epoch 12/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8866 - loss: 0.3206 - val_accuracy: 0.4318 - val_loss: 2.4651\n",
            "Epoch 13/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9296 - loss: 0.2282 - val_accuracy: 0.4036 - val_loss: 2.8569\n",
            "Epoch 14/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2253 - val_accuracy: 0.3808 - val_loss: 3.4453\n",
            "Epoch 15/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8967 - loss: 0.2934 - val_accuracy: 0.3600 - val_loss: 3.9276\n",
            "Epoch 16/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8929 - loss: 0.3279 - val_accuracy: 0.4164 - val_loss: 3.4894\n",
            "Epoch 17/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9507 - loss: 0.1479 - val_accuracy: 0.4043 - val_loss: 3.4243\n",
            "Epoch 18/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9385 - loss: 0.1655 - val_accuracy: 0.3909 - val_loss: 4.7962\n",
            "Epoch 19/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8500 - loss: 0.4676 - val_accuracy: 0.4070 - val_loss: 3.6901\n",
            "Epoch 20/20\n",
            "\u001b[1m373/373\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0915 - val_accuracy: 0.3727 - val_loss: 3.8518\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Reshape\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path to dataset\n",
        "DATA_PATH = \"archive (1)/AudioWAV\"  # Update with actual path\n",
        "\n",
        "# Emotion Mapping (based on filenames)\n",
        "EMOTION_MAPPING = {\n",
        "    \"ANG\": \"Anger\",\n",
        "    \"DIS\": \"Disgust\",\n",
        "    \"FEA\": \"Fear\",\n",
        "    \"HAP\": \"Happy\",\n",
        "    \"SAD\": \"Sadness\",\n",
        "    \"SUR\": \"Surprise\",\n",
        "    \"NEU\": \"Neutral\"\n",
        "}\n",
        "EMOTIONS = list(EMOTION_MAPPING.values())  # Define emotion classes\n",
        "\n",
        "# Fixed time-step length\n",
        "MAX_PAD_LENGTH = 100  # Ensures uniform input size\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_features(file_path, max_pad_length=MAX_PAD_LENGTH):\n",
        "    y, sr = librosa.load(file_path, sr=22050)\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)  # Shape: (40, time_steps)\n",
        "\n",
        "    # Pad or truncate MFCC to a fixed shape (40, 100)\n",
        "    if mfccs.shape[1] < max_pad_length:\n",
        "        pad_width = max_pad_length - mfccs.shape[1]\n",
        "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        mfccs = mfccs[:, :max_pad_length]\n",
        "\n",
        "    return np.expand_dims(mfccs, axis=-1)  # Keep it in (40, 100, 1)\n",
        "\n",
        "# Load dataset\n",
        "X, y = [], []\n",
        "for file in os.listdir(DATA_PATH):\n",
        "    if file.endswith(\".wav\"):\n",
        "        file_path = os.path.join(DATA_PATH, file)\n",
        "        parts = file.split(\"_\")  # Extract emotion from filename\n",
        "        if len(parts) > 2:\n",
        "            emotion_label = parts[2]  # Third part of filename (e.g., \"SAD\")\n",
        "            if emotion_label in EMOTION_MAPPING:\n",
        "                features = extract_features(file_path)  # Shape (40, 100, 1)\n",
        "                X.append(features)\n",
        "                y.append(EMOTIONS.index(EMOTION_MAPPING[emotion_label]))\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X = np.array(X)  # Shape: (num_samples, 40, 100, 1)\n",
        "y = to_categorical(np.array(y), num_classes=len(EMOTIONS))\n",
        "\n",
        "# Ensure data is loaded\n",
        "if len(X) == 0:\n",
        "    raise ValueError(\"No audio files were processed. Check dataset path or structure.\")\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Corrected Model Architecture\n",
        "model = Sequential([\n",
        "    Reshape((40, 100, 1), input_shape=(40, 100, 1)),  # Ensure correct shape\n",
        "    Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),  # No TimeDistributed needed\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(len(EMOTIONS), activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save Model\n",
        "model.save(\"emotion_model.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPDse8SS-ao_",
        "outputId": "ae63f8a6-857e-46d3-dbac-242a48f88f79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  archive (1).zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of archive (1).zip or\n",
            "        archive (1).zip.zip, and cannot find archive (1).zip.ZIP, period.\n"
          ]
        }
      ],
      "source": [
        "!unzip archive\\ \\(1\\).zip -d archive\\ \\(1\\)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}